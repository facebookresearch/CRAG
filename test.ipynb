{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"interaction_id\": \"7bb29eb4-12f9-45f9-bf8a-66832b3c8962\", \"query_time\": \"03/10/2024, 23:19:21 PT\", \"domain\": \"sports\", \"question_type\": \"post-processing\", \"static_or_dynamic\": \"static\", \"query\": \"how many 3-point attempts did s\n"
     ]
    }
   ],
   "source": [
    "import bz2\n",
    "\n",
    "file_path = \"/Users/a1/github_reps/butterboard_CRAG/data/crag_task_1_and_2_dev_v4.jsonl.bz2\"\n",
    "\n",
    "with bz2.open(file_path, \"rt\", encoding=\"utf-8\") as f:\n",
    "    print(f.readline(228))  # Вывести первую строку файла"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering the long-tailed questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered 10 long-tailed questions saved to data/filtered_long_tailed_questions_test.jsonl\n"
     ]
    }
   ],
   "source": [
    "import bz2\n",
    "import json\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "CRAG_DATA_PATH = \"data/crag_task_1_and_2_dev_v4.jsonl.bz2\"\n",
    "FILTERED_DATA_PATH = \"data/filtered_long_tailed_questions_test.jsonl\"\n",
    "\n",
    "# Define long-tailed question criteria\n",
    "RARE_THRESHOLD = 5  # Words appearing less than 5 times\n",
    "LONG_TAIL_TYPES = [\"multi-hop\", \"comparison\", \"false_premise\"]  # Harder question types\n",
    "SAMPLE_SIZE = 10  # Limit dataset size\n",
    "\n",
    "def load_crag_data(filepath):\n",
    "    \"\"\"Load CRAG dataset from bz2 compressed JSONL format.\"\"\"\n",
    "    with bz2.open(filepath, \"rt\") as f:\n",
    "        return [json.loads(line) for line in f]\n",
    "\n",
    "def filter_long_tailed_questions(data):\n",
    "    \"\"\"Extract long-tailed questions using word frequency and question type.\"\"\"\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Compute word frequencies\n",
    "    all_words = \" \".join(df[\"query\"]).split()\n",
    "    word_counts = Counter(all_words)\n",
    "\n",
    "    def is_long_tailed(query, question_type):\n",
    "        words = query.split()\n",
    "        rare_words = [word for word in words if word_counts[word] < RARE_THRESHOLD]\n",
    "        return len(rare_words) > 2 or question_type in LONG_TAIL_TYPES\n",
    "\n",
    "    filtered_df = df[df.apply(lambda row: is_long_tailed(row[\"query\"], row[\"question_type\"]), axis=1)]\n",
    "    return filtered_df.sample(n=min(SAMPLE_SIZE, len(filtered_df)), random_state=42)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    crag_data = load_crag_data(CRAG_DATA_PATH)\n",
    "    filtered_data = filter_long_tailed_questions(crag_data)\n",
    "    \n",
    "    # Save filtered dataset\n",
    "    with open(FILTERED_DATA_PATH, \"w\") as f:\n",
    "        for record in filtered_data.to_dict(orient=\"records\"):\n",
    "            f.write(json.dumps(record) + \"\\n\")\n",
    "\n",
    "    print(f\"Filtered {len(filtered_data)} long-tailed questions saved to {FILTERED_DATA_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating limited balanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced dataset with 80 questions saved to data/balanced_100_questions.jsonl\n"
     ]
    }
   ],
   "source": [
    "import bz2\n",
    "import json\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "CRAG_DATA_PATH = \"data/crag_task_1_and_2_dev_v4.jsonl.bz2\"\n",
    "FILTERED_DATA_PATH = \"data/balanced_100_questions.jsonl\"\n",
    "SAMPLE_PER_CATEGORY = 10  # Number of questions per category\n",
    "\n",
    "def load_crag_data(filepath):\n",
    "    \"\"\"Load CRAG dataset from bz2 compressed JSONL format.\"\"\"\n",
    "    with bz2.open(filepath, \"rt\") as f:\n",
    "        return [json.loads(line) for line in f]\n",
    "\n",
    "def sample_balanced_questions(data):\n",
    "    \"\"\"Select an equal number of questions from each category.\"\"\"\n",
    "    df = pd.DataFrame(data)\n",
    "    categories = df[\"question_type\"].unique()\n",
    "    \n",
    "    sampled_dfs = []\n",
    "    for category in categories:\n",
    "        category_df = df[df[\"question_type\"] == category]\n",
    "        sampled_dfs.append(category_df.sample(n=min(SAMPLE_PER_CATEGORY, len(category_df)), random_state=42))\n",
    "    \n",
    "    return pd.concat(sampled_dfs)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    crag_data = load_crag_data(CRAG_DATA_PATH)\n",
    "    balanced_data = sample_balanced_questions(crag_data)\n",
    "    \n",
    "    # Save balanced dataset\n",
    "    with open(FILTERED_DATA_PATH, \"w\") as f:\n",
    "        for record in balanced_data.to_dict(orient=\"records\"):\n",
    "            f.write(json.dumps(record) + \"\\n\")\n",
    "\n",
    "    print(f\"Balanced dataset with {len(balanced_data)} questions saved to {FILTERED_DATA_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compressing files to bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressed data/filtered_long_tailed_questions_test.jsonl to data/filtered_long_tailed_questions_test.jsonl.bz2\n"
     ]
    }
   ],
   "source": [
    "import bz2\n",
    "import json\n",
    "\n",
    "def compress_jsonl_to_bz2(jsonl_path, bz2_path):\n",
    "    with open(jsonl_path, 'rt') as jsonl_file, bz2.open(bz2_path, 'wt') as bz2_file:\n",
    "        for line in jsonl_file:\n",
    "            bz2_file.write(line)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    jsonl_path = 'data/filtered_long_tailed_questions_test.jsonl'  # Replace with the path to your JSONL file\n",
    "    bz2_path = 'data/filtered_long_tailed_questions_test.jsonl.bz2'  # Replace with the desired output path\n",
    "\n",
    "    compress_jsonl_to_bz2(jsonl_path, bz2_path)\n",
    "    print(f\"Compressed {jsonl_path} to {bz2_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressed data/balanced_100_questions.jsonl to data/balanced_100_questions.jsonl.bz2\n"
     ]
    }
   ],
   "source": [
    "import bz2\n",
    "import json\n",
    "\n",
    "def compress_jsonl_to_bz2(jsonl_path, bz2_path):\n",
    "    with open(jsonl_path, 'rt') as jsonl_file, bz2.open(bz2_path, 'wt') as bz2_file:\n",
    "        for line in jsonl_file:\n",
    "            bz2_file.write(line)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    jsonl_path = 'data/balanced_100_questions.jsonl'  # Replace with the path to your JSONL file\n",
    "    bz2_path = 'data/balanced_100_questions.jsonl.bz2'  # Replace with the desired output path\n",
    "\n",
    "    compress_jsonl_to_bz2(jsonl_path, bz2_path)\n",
    "    print(f\"Compressed {jsonl_path} to {bz2_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
